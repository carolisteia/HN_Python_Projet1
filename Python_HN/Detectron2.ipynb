{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bLbg_T7vI6jx","executionInfo":{"status":"ok","timestamp":1686418268755,"user_tz":-120,"elapsed":1897,"user":{"displayName":"Nina","userId":"17252847072102429143"}},"outputId":"f8f8ecfa-c7bd-4b12-b0f2-c8873bb5cd62"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!python -m pip install pyyaml==5.1\n","import sys, os, distutils.core\n","# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n","# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n","!git clone 'https://github.com/facebookresearch/detectron2'\n","dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n","!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n","sys.path.insert(0, os.path.abspath('./detectron2'))\n","\n","# Properly install detectron2. (Please do not install twice in both ways)\n","# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cc-X_w5oIm_u","executionInfo":{"status":"ok","timestamp":1686418283714,"user_tz":-120,"elapsed":14966,"user":{"displayName":"Nina","userId":"17252847072102429143"}},"outputId":"3f6586c5-8b61-4ae5-b91b-ccccd0cde72f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.10/dist-packages (5.1)\n","fatal: destination path 'detectron2' already exists and is not an empty directory.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (8.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.6)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.10/dist-packages (0.1.8)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.8.10)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (2.2.1)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (4.65.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.2)\n","Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (0.1.5.post20221221)\n","Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (0.1.9)\n","Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.10/dist-packages (1.3.2)\n","Requirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (23.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (23.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs>=0.1.8) (5.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.54.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.3)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.40.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7) (2.7.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.1) (4.9.3)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black) (8.1.3)\n","Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black) (1.0.0)\n","Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black) (0.11.1)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black) (3.3.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black) (2.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"]}]},{"cell_type":"code","source":["import torch, detectron2\n","!nvcc --version\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","print(\"detectron2:\", detectron2.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lw2GoxO3Iu1N","executionInfo":{"status":"ok","timestamp":1686418284033,"user_tz":-120,"elapsed":329,"user":{"displayName":"Nina","userId":"17252847072102429143"}},"outputId":"b1d53593-60e0-4976-c164-361d2b6471bb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n","torch:  2.0 ; cuda:  cu118\n","detectron2: 0.6\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ZyAvNCJMmvFF","executionInfo":{"status":"ok","timestamp":1686418284416,"user_tz":-120,"elapsed":386,"user":{"displayName":"Nina","userId":"17252847072102429143"}}},"outputs":[],"source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","import matplotlib.pyplot as plt\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","from detectron2.data.datasets import register_coco_instances\n","from detectron2.engine import DefaultTrainer\n","from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","from detectron2.utils.visualizer import ColorMode"]},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/Python_HN\")"],"metadata":{"id":"YMiErn4FJrHk","executionInfo":{"status":"ok","timestamp":1686418284420,"user_tz":-120,"elapsed":17,"user":{"displayName":"Nina","userId":"17252847072102429143"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"D_S5RmxcHw1d","executionInfo":{"status":"ok","timestamp":1686418284422,"user_tz":-120,"elapsed":18,"user":{"displayName":"Nina","userId":"17252847072102429143"}}},"outputs":[],"source":["def exec_d2(name,n_classes):\n","    register_coco_instances(name + \"_train\", {}, \"./coco/coco_annotations_\" + name + \"_train.json\", \"./image_dir\")\n","    register_coco_instances(name + \"_val\", {}, \"./coco/coco_annotations_\" + name + \"_val.json\", \"./image_dir\")\n","    \n","    metadata = MetadataCatalog.get(name + \"_train\")\n","    dataset_dicts = DatasetCatalog.get(name + \"_train\")\n","    \n","    cfg = get_cfg()\n","    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","    cfg.DATASETS.TRAIN = (name + \"_train\",)\n","    cfg.DATASETS.TEST = ()\n","    cfg.DATALOADER.NUM_WORKERS = 1\n","    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n","    cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n","    cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n","    if name == \"yaelle\":\n","        cfg.SOLVER.MAX_ITER = 1500    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n","    else:\n","        cfg.SOLVER.MAX_ITER = 1000\n","    cfg.SOLVER.STEPS = []        # do not decay learning rate\n","    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n","    cfg.MODEL.ROI_HEADS.NUM_CLASSES = n_classes  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n","    \n","    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","    trainer = DefaultTrainer(cfg) \n","    trainer.resume_or_load(resume=False)\n","    trainer.train()\n","    \n","    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n","    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n","    predictor = DefaultPredictor(cfg)\n","    \n","    evaluator = COCOEvaluator(name + \"_val\", output_dir=\"./output\")\n","    val_loader = build_detection_test_loader(cfg, name + \"_val\")\n","    f = open(name + '_val_results.txt', 'w+')\n","    print(inference_on_dataset(predictor.model, val_loader, evaluator), file = f)\n","    \n","    return(predictor,metadata)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"WhjyoXLuHw1f","executionInfo":{"status":"ok","timestamp":1686418284423,"user_tz":-120,"elapsed":17,"user":{"displayName":"Nina","userId":"17252847072102429143"}}},"outputs":[],"source":["def classify(name,predictor):\n","    img_cl = []\n","\n","    # creates a ScandirIterator aliased as files\n","    with os.scandir('images') as files:\n","      # loops through each file in the directory\n","        for file in files:\n","            img_cl.append(file.name)\n","    \n","    if name == \"yaelle\":\n","        count = {}\n","        for i in img_cl:\n","            im = cv2.imread('images/' + i)\n","            outputs = predictor(im)\n","            hm = 0\n","            fm = 0\n","            ef = 0\n","            nn = 0\n","            for j in outputs[\"instances\"].pred_classes:\n","                if j == 0:\n","                    hm += 1\n","                elif j == 1:\n","                    fm += 1\n","                elif j == 2:\n","                    ef += 1\n","                elif j == 3:\n","                    nn += 1\n","            nb = str(hm) + '_' + str(fm) + '_' + str(ef) + '_' + str(nn)\n","            if nb not in count.keys():\n","                count[nb] = []\n","                count[nb].append(i)\n","            else:\n","                count[nb].append(i)\n","    else:\n","        count = {}\n","        for i in img_cl:\n","            im = cv2.imread('images/' + i)\n","            outputs = predictor(im)\n","            v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.5, instance_mode=ColorMode.IMAGE_BW)\n","            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","            im_mask = out.get_image()[:, :, ::-1]\n","            nb = len(outputs[\"instances\"])\n","            if nb not in count.keys():\n","                count[nb] = []\n","                count[nb + '_masks'] = []\n","                count[nb].append(i)\n","                \n","            else:\n","                count[nb].append(i)\n","    \n","    for nb in count.keys():\n","        nb_path = name + '/' + str(nb)\n","        os.mkdir(nb_path)\n","        for filename in count[nb]:\n","            print(filename)\n","            file = cv2.imread('images/' + filename)\n","            cv2.imwrite(nb_path + '/' + filename,file)\n","        "]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Ok-15Ha01uNe","executionInfo":{"status":"ok","timestamp":1686418284424,"user_tz":-120,"elapsed":17,"user":{"displayName":"Nina","userId":"17252847072102429143"}}},"outputs":[],"source":["def classify(name,predictor):\n","    img_cl = []\n","\n","    # creates a ScandirIterator aliased as files\n","    with os.scandir('images') as files:\n","      # loops through each file in the directory\n","        for file in files:\n","            img_cl.append(file.name)\n","    \n","    if name == \"yaelle\":\n","        count = {}\n","        for i in img_cl:\n","            im = cv2.imread('images/' + i)\n","            outputs = predictor(im)\n","            v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.5, instance_mode=ColorMode.IMAGE_BW)\n","            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","            im_mask = out.get_image()[:, :, ::-1]\n","            hm = 0\n","            fm = 0\n","            ef = 0\n","            nn = 0\n","            for j in outputs[\"instances\"].pred_classes:\n","                if j == 0:\n","                    hm += 1\n","                elif j == 1:\n","                    fm += 1\n","                elif j == 2:\n","                    ef += 1\n","                elif j == 3:\n","                    nn += 1\n","            nb = str(hm) + '_' + str(fm) + '_' + str(ef) + '_' + str(nn)\n","            if nb not in count.keys():\n","                count[nb] = []\n","                count[nb + '_masks'] = []\n","                count[nb].append(i)\n","                count[nb + '_masks'].append(im_mask)\n","            else:\n","                count[nb].append(i)\n","                count[nb + '_masks'].append(im_mask)\n","    else:\n","        count = {}\n","        for i in img_cl:\n","            im = cv2.imread('images/' + i)\n","            outputs = predictor(im)\n","            v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.5, instance_mode=ColorMode.IMAGE_BW)\n","            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","            im_mask = out.get_image()[:, :, ::-1]\n","            nb = len(outputs[\"instances\"])\n","            if str(nb) not in count.keys():\n","                count[str(nb)] = []\n","                count[str(nb) + '_masks'] = []\n","                count[str(nb)].append(i)\n","                count[str(nb) + '_masks'].append(im_mask)\n","            else:\n","                count[str(nb)].append(i)\n","                count[str(nb) + '_masks'].append(im_mask)\n","    \n","    for nb in count.keys():\n","        if not 'masks' in nb:\n","            nb_path = name + '/' + str(nb)\n","            os.mkdir(nb_path)\n","            for i in range(len(count[nb])):\n","                file = cv2.imread('images/' + count[nb][i])\n","                cv2.imwrite(nb_path + '/' + count[nb][i],count[str(nb) + '_masks'][i])\n","        "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"jrBvXVRQHw1h","executionInfo":{"status":"ok","timestamp":1686418284425,"user_tz":-120,"elapsed":16,"user":{"displayName":"Nina","userId":"17252847072102429143"}}},"outputs":[],"source":["names = {}\n","names['yaelle'] = 4\n","names['chen'] = 1\n","names['lise'] = 1\n","names['ekaterina'] = 1\n","names['noe'] = 1"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TFV5JtOuHw1i","executionInfo":{"status":"ok","timestamp":1686418845646,"user_tz":-120,"elapsed":561237,"user":{"displayName":"Nina","userId":"17252847072102429143"}},"outputId":"61c34eb2-c0e2-46f9-8bce-ac5cee4a67e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[06/10 17:31:23 d2.data.datasets.coco]: Loaded 100 images in COCO format from ./coco/coco_annotations_noe_train.json\n","[06/10 17:31:26 d2.engine.defaults]: Model:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","[06/10 17:31:26 d2.data.datasets.coco]: Loaded 100 images in COCO format from ./coco/coco_annotations_noe_train.json\n","[06/10 17:31:26 d2.data.build]: Removed 0 images with no usable annotations. 100 images left.\n","[06/10 17:31:26 d2.data.build]: Distribution of instances among all 1 categories:\n","|  category  | #instances   |\n","|:----------:|:-------------|\n","|   Human    | 392          |\n","|            |              |\n","[06/10 17:31:26 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","[06/10 17:31:26 d2.data.build]: Using training sampler TrainingSampler\n","[06/10 17:31:26 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[06/10 17:31:26 d2.data.common]: Serializing 100 elements to byte tensors and concatenating them all ...\n","[06/10 17:31:26 d2.data.common]: Serialized dataset takes 0.10 MiB\n","[06/10 17:31:26 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n","roi_heads.box_predictor.bbox_pred.{bias, weight}\n","roi_heads.box_predictor.cls_score.{bias, weight}\n","roi_heads.mask_head.predictor.{bias, weight}\n"]},{"output_type":"stream","name":"stdout","text":["[06/10 17:31:26 d2.engine.train_loop]: Starting training from iteration 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["[06/10 17:31:40 d2.utils.events]:  eta: 0:08:22  iter: 19  total_loss: 2.458  loss_cls: 0.7948  loss_box_reg: 0.8986  loss_mask: 0.6936  loss_rpn_cls: 0.0356  loss_rpn_loc: 0.02976    time: 0.5346  last_time: 0.3552  data_time: 0.0504  last_data_time: 0.0038   lr: 4.9953e-06  max_mem: 2454M\n","[06/10 17:31:54 d2.utils.events]:  eta: 0:08:08  iter: 39  total_loss: 2.36  loss_cls: 0.7521  loss_box_reg: 0.8369  loss_mask: 0.6912  loss_rpn_cls: 0.01954  loss_rpn_loc: 0.01399    time: 0.5383  last_time: 0.4352  data_time: 0.0264  last_data_time: 0.0076   lr: 9.9902e-06  max_mem: 2454M\n","[06/10 17:32:04 d2.utils.events]:  eta: 0:07:50  iter: 59  total_loss: 2.244  loss_cls: 0.6478  loss_box_reg: 0.8067  loss_mask: 0.6839  loss_rpn_cls: 0.04025  loss_rpn_loc: 0.01784    time: 0.5238  last_time: 0.4859  data_time: 0.0193  last_data_time: 0.0192   lr: 1.4985e-05  max_mem: 2454M\n","[06/10 17:32:13 d2.utils.events]:  eta: 0:07:32  iter: 79  total_loss: 2.194  loss_cls: 0.5495  loss_box_reg: 0.8933  loss_mask: 0.6745  loss_rpn_cls: 0.02428  loss_rpn_loc: 0.02292    time: 0.5106  last_time: 0.4990  data_time: 0.0181  last_data_time: 0.0446   lr: 1.998e-05  max_mem: 2454M\n","[06/10 17:32:23 d2.utils.events]:  eta: 0:07:22  iter: 99  total_loss: 2.136  loss_cls: 0.5122  loss_box_reg: 0.8539  loss_mask: 0.6666  loss_rpn_cls: 0.02199  loss_rpn_loc: 0.01962    time: 0.5073  last_time: 0.5176  data_time: 0.0158  last_data_time: 0.0037   lr: 2.4975e-05  max_mem: 2455M\n","[06/10 17:32:34 d2.utils.events]:  eta: 0:07:16  iter: 119  total_loss: 2.052  loss_cls: 0.463  loss_box_reg: 0.8682  loss_mask: 0.6461  loss_rpn_cls: 0.02945  loss_rpn_loc: 0.02125    time: 0.5096  last_time: 0.5598  data_time: 0.0184  last_data_time: 0.0205   lr: 2.997e-05  max_mem: 2455M\n","[06/10 17:32:43 d2.utils.events]:  eta: 0:07:06  iter: 139  total_loss: 1.922  loss_cls: 0.4129  loss_box_reg: 0.8085  loss_mask: 0.6379  loss_rpn_cls: 0.01911  loss_rpn_loc: 0.02642    time: 0.5055  last_time: 0.5397  data_time: 0.0119  last_data_time: 0.0032   lr: 3.4965e-05  max_mem: 2456M\n","[06/10 17:32:54 d2.utils.events]:  eta: 0:06:59  iter: 159  total_loss: 1.9  loss_cls: 0.4076  loss_box_reg: 0.8731  loss_mask: 0.6077  loss_rpn_cls: 0.01562  loss_rpn_loc: 0.01344    time: 0.5070  last_time: 0.4920  data_time: 0.0189  last_data_time: 0.0147   lr: 3.996e-05  max_mem: 2456M\n","[06/10 17:33:03 d2.utils.events]:  eta: 0:06:48  iter: 179  total_loss: 1.89  loss_cls: 0.3834  loss_box_reg: 0.8553  loss_mask: 0.5946  loss_rpn_cls: 0.02461  loss_rpn_loc: 0.0228    time: 0.5048  last_time: 0.4566  data_time: 0.0221  last_data_time: 0.0112   lr: 4.4955e-05  max_mem: 2456M\n","[06/10 17:33:13 d2.utils.events]:  eta: 0:06:34  iter: 199  total_loss: 1.835  loss_cls: 0.3743  loss_box_reg: 0.8086  loss_mask: 0.5742  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.02093    time: 0.5016  last_time: 0.4850  data_time: 0.0129  last_data_time: 0.0070   lr: 4.995e-05  max_mem: 2456M\n","[06/10 17:33:23 d2.utils.events]:  eta: 0:06:24  iter: 219  total_loss: 1.78  loss_cls: 0.3362  loss_box_reg: 0.8301  loss_mask: 0.5404  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.01618    time: 0.5001  last_time: 0.4156  data_time: 0.0205  last_data_time: 0.0061   lr: 5.4945e-05  max_mem: 2456M\n","[06/10 17:33:32 d2.utils.events]:  eta: 0:06:13  iter: 239  total_loss: 1.753  loss_cls: 0.3416  loss_box_reg: 0.8321  loss_mask: 0.5115  loss_rpn_cls: 0.01739  loss_rpn_loc: 0.02341    time: 0.4983  last_time: 0.5106  data_time: 0.0204  last_data_time: 0.0636   lr: 5.994e-05  max_mem: 2456M\n","[06/10 17:33:42 d2.utils.events]:  eta: 0:06:03  iter: 259  total_loss: 1.585  loss_cls: 0.3158  loss_box_reg: 0.7929  loss_mask: 0.4773  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.01303    time: 0.4966  last_time: 0.4783  data_time: 0.0183  last_data_time: 0.0076   lr: 6.4935e-05  max_mem: 2456M\n","[06/10 17:33:52 d2.utils.events]:  eta: 0:05:54  iter: 279  total_loss: 1.615  loss_cls: 0.31  loss_box_reg: 0.8136  loss_mask: 0.4391  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.02284    time: 0.4965  last_time: 0.4193  data_time: 0.0207  last_data_time: 0.0474   lr: 6.993e-05  max_mem: 2456M\n","[06/10 17:34:02 d2.utils.events]:  eta: 0:05:45  iter: 299  total_loss: 1.526  loss_cls: 0.2826  loss_box_reg: 0.7638  loss_mask: 0.4042  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.01531    time: 0.4985  last_time: 0.5471  data_time: 0.0215  last_data_time: 0.0051   lr: 7.4925e-05  max_mem: 2456M\n","[06/10 17:34:12 d2.utils.events]:  eta: 0:05:35  iter: 319  total_loss: 1.319  loss_cls: 0.2444  loss_box_reg: 0.7279  loss_mask: 0.3705  loss_rpn_cls: 0.01499  loss_rpn_loc: 0.01656    time: 0.4980  last_time: 0.4307  data_time: 0.0205  last_data_time: 0.0066   lr: 7.992e-05  max_mem: 2456M\n","[06/10 17:34:22 d2.utils.events]:  eta: 0:05:25  iter: 339  total_loss: 1.312  loss_cls: 0.2433  loss_box_reg: 0.7056  loss_mask: 0.3421  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.01745    time: 0.4971  last_time: 0.5371  data_time: 0.0181  last_data_time: 0.0073   lr: 8.4915e-05  max_mem: 2456M\n","[06/10 17:34:32 d2.utils.events]:  eta: 0:05:16  iter: 359  total_loss: 1.324  loss_cls: 0.2492  loss_box_reg: 0.698  loss_mask: 0.3194  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.0176    time: 0.4976  last_time: 0.5258  data_time: 0.0221  last_data_time: 0.0055   lr: 8.991e-05  max_mem: 2456M\n","[06/10 17:34:41 d2.utils.events]:  eta: 0:05:05  iter: 379  total_loss: 1.092  loss_cls: 0.1851  loss_box_reg: 0.5742  loss_mask: 0.2831  loss_rpn_cls: 0.007842  loss_rpn_loc: 0.01895    time: 0.4962  last_time: 0.4713  data_time: 0.0169  last_data_time: 0.0083   lr: 9.4905e-05  max_mem: 2456M\n","[06/10 17:34:51 d2.utils.events]:  eta: 0:04:55  iter: 399  total_loss: 1.138  loss_cls: 0.1935  loss_box_reg: 0.5857  loss_mask: 0.2878  loss_rpn_cls: 0.0054  loss_rpn_loc: 0.01536    time: 0.4963  last_time: 0.3633  data_time: 0.0153  last_data_time: 0.0040   lr: 9.99e-05  max_mem: 2456M\n","[06/10 17:35:01 d2.utils.events]:  eta: 0:04:45  iter: 419  total_loss: 1.125  loss_cls: 0.1944  loss_box_reg: 0.5727  loss_mask: 0.3013  loss_rpn_cls: 0.01005  loss_rpn_loc: 0.01946    time: 0.4960  last_time: 0.5506  data_time: 0.0218  last_data_time: 0.0065   lr: 0.0001049  max_mem: 2456M\n","[06/10 17:35:11 d2.utils.events]:  eta: 0:04:36  iter: 439  total_loss: 0.9401  loss_cls: 0.1804  loss_box_reg: 0.4744  loss_mask: 0.2782  loss_rpn_cls: 0.008328  loss_rpn_loc: 0.01527    time: 0.4965  last_time: 0.5375  data_time: 0.0174  last_data_time: 0.0035   lr: 0.00010989  max_mem: 2456M\n","[06/10 17:35:21 d2.utils.events]:  eta: 0:04:27  iter: 459  total_loss: 0.8617  loss_cls: 0.1744  loss_box_reg: 0.4384  loss_mask: 0.248  loss_rpn_cls: 0.006495  loss_rpn_loc: 0.01135    time: 0.4971  last_time: 0.4207  data_time: 0.0211  last_data_time: 0.0042   lr: 0.00011489  max_mem: 2456M\n","[06/10 17:35:31 d2.utils.events]:  eta: 0:04:17  iter: 479  total_loss: 1.085  loss_cls: 0.2228  loss_box_reg: 0.493  loss_mask: 0.2727  loss_rpn_cls: 0.007383  loss_rpn_loc: 0.02018    time: 0.4970  last_time: 0.4119  data_time: 0.0230  last_data_time: 0.0071   lr: 0.00011988  max_mem: 2456M\n","[06/10 17:35:41 d2.utils.events]:  eta: 0:04:07  iter: 499  total_loss: 0.8715  loss_cls: 0.1762  loss_box_reg: 0.3861  loss_mask: 0.2587  loss_rpn_cls: 0.005317  loss_rpn_loc: 0.01663    time: 0.4963  last_time: 0.4040  data_time: 0.0182  last_data_time: 0.0062   lr: 0.00012488  max_mem: 2456M\n","[06/10 17:35:51 d2.utils.events]:  eta: 0:03:57  iter: 519  total_loss: 0.8062  loss_cls: 0.1435  loss_box_reg: 0.3812  loss_mask: 0.2498  loss_rpn_cls: 0.006317  loss_rpn_loc: 0.01576    time: 0.4964  last_time: 0.4959  data_time: 0.0183  last_data_time: 0.0062   lr: 0.00012987  max_mem: 2456M\n","[06/10 17:36:01 d2.utils.events]:  eta: 0:03:47  iter: 539  total_loss: 0.8129  loss_cls: 0.156  loss_box_reg: 0.3661  loss_mask: 0.2602  loss_rpn_cls: 0.009235  loss_rpn_loc: 0.01619    time: 0.4966  last_time: 0.5336  data_time: 0.0203  last_data_time: 0.0122   lr: 0.00013487  max_mem: 2456M\n","[06/10 17:36:10 d2.utils.events]:  eta: 0:03:37  iter: 559  total_loss: 0.7741  loss_cls: 0.1396  loss_box_reg: 0.3542  loss_mask: 0.2293  loss_rpn_cls: 0.003473  loss_rpn_loc: 0.01513    time: 0.4958  last_time: 0.4472  data_time: 0.0180  last_data_time: 0.0050   lr: 0.00013986  max_mem: 2456M\n","[06/10 17:36:20 d2.utils.events]:  eta: 0:03:27  iter: 579  total_loss: 0.7392  loss_cls: 0.1324  loss_box_reg: 0.3454  loss_mask: 0.2218  loss_rpn_cls: 0.0042  loss_rpn_loc: 0.01381    time: 0.4959  last_time: 0.4747  data_time: 0.0148  last_data_time: 0.0088   lr: 0.00014486  max_mem: 2456M\n","[06/10 17:36:30 d2.utils.events]:  eta: 0:03:17  iter: 599  total_loss: 0.8316  loss_cls: 0.1833  loss_box_reg: 0.3961  loss_mask: 0.2427  loss_rpn_cls: 0.002764  loss_rpn_loc: 0.01326    time: 0.4960  last_time: 0.4850  data_time: 0.0149  last_data_time: 0.0099   lr: 0.00014985  max_mem: 2456M\n","[06/10 17:36:41 d2.utils.events]:  eta: 0:03:08  iter: 619  total_loss: 0.6874  loss_cls: 0.1216  loss_box_reg: 0.3186  loss_mask: 0.2307  loss_rpn_cls: 0.0009902  loss_rpn_loc: 0.01231    time: 0.4963  last_time: 0.5375  data_time: 0.0189  last_data_time: 0.0037   lr: 0.00015485  max_mem: 2456M\n","[06/10 17:36:50 d2.utils.events]:  eta: 0:02:57  iter: 639  total_loss: 0.7521  loss_cls: 0.1265  loss_box_reg: 0.3561  loss_mask: 0.2254  loss_rpn_cls: 0.003899  loss_rpn_loc: 0.01306    time: 0.4954  last_time: 0.4895  data_time: 0.0174  last_data_time: 0.0045   lr: 0.00015984  max_mem: 2456M\n","[06/10 17:37:00 d2.utils.events]:  eta: 0:02:48  iter: 659  total_loss: 0.7141  loss_cls: 0.1262  loss_box_reg: 0.3299  loss_mask: 0.2191  loss_rpn_cls: 0.003526  loss_rpn_loc: 0.01719    time: 0.4963  last_time: 0.5472  data_time: 0.0208  last_data_time: 0.0138   lr: 0.00016484  max_mem: 2456M\n","[06/10 17:37:10 d2.utils.events]:  eta: 0:02:38  iter: 679  total_loss: 0.7062  loss_cls: 0.1082  loss_box_reg: 0.3292  loss_mask: 0.2441  loss_rpn_cls: 0.007064  loss_rpn_loc: 0.01347    time: 0.4960  last_time: 0.4436  data_time: 0.0152  last_data_time: 0.0186   lr: 0.00016983  max_mem: 2456M\n","[06/10 17:37:20 d2.utils.events]:  eta: 0:02:28  iter: 699  total_loss: 0.5735  loss_cls: 0.1163  loss_box_reg: 0.2972  loss_mask: 0.1797  loss_rpn_cls: 0.002437  loss_rpn_loc: 0.0111    time: 0.4960  last_time: 0.4313  data_time: 0.0163  last_data_time: 0.0031   lr: 0.00017483  max_mem: 2456M\n","[06/10 17:37:30 d2.utils.events]:  eta: 0:02:18  iter: 719  total_loss: 0.6401  loss_cls: 0.1085  loss_box_reg: 0.2844  loss_mask: 0.1993  loss_rpn_cls: 0.00104  loss_rpn_loc: 0.0122    time: 0.4964  last_time: 0.4361  data_time: 0.0258  last_data_time: 0.0068   lr: 0.00017982  max_mem: 2456M\n","[06/10 17:37:40 d2.utils.events]:  eta: 0:02:08  iter: 739  total_loss: 0.5874  loss_cls: 0.1012  loss_box_reg: 0.2797  loss_mask: 0.231  loss_rpn_cls: 0.00404  loss_rpn_loc: 0.01994    time: 0.4967  last_time: 0.5012  data_time: 0.0204  last_data_time: 0.0186   lr: 0.00018482  max_mem: 2456M\n","[06/10 17:37:50 d2.utils.events]:  eta: 0:01:58  iter: 759  total_loss: 0.6468  loss_cls: 0.1278  loss_box_reg: 0.29  loss_mask: 0.2245  loss_rpn_cls: 0.003617  loss_rpn_loc: 0.01467    time: 0.4967  last_time: 0.4629  data_time: 0.0171  last_data_time: 0.0050   lr: 0.00018981  max_mem: 2456M\n","[06/10 17:38:01 d2.utils.events]:  eta: 0:01:49  iter: 779  total_loss: 0.6176  loss_cls: 0.1025  loss_box_reg: 0.2876  loss_mask: 0.207  loss_rpn_cls: 0.001949  loss_rpn_loc: 0.01387    time: 0.4971  last_time: 0.5737  data_time: 0.0150  last_data_time: 0.0519   lr: 0.00019481  max_mem: 2456M\n","[06/10 17:38:10 d2.utils.events]:  eta: 0:01:39  iter: 799  total_loss: 0.6647  loss_cls: 0.1309  loss_box_reg: 0.295  loss_mask: 0.2179  loss_rpn_cls: 0.003342  loss_rpn_loc: 0.01636    time: 0.4969  last_time: 0.4452  data_time: 0.0190  last_data_time: 0.0031   lr: 0.0001998  max_mem: 2456M\n","[06/10 17:38:20 d2.utils.events]:  eta: 0:01:29  iter: 819  total_loss: 0.5776  loss_cls: 0.09461  loss_box_reg: 0.279  loss_mask: 0.2055  loss_rpn_cls: 0.001328  loss_rpn_loc: 0.01085    time: 0.4963  last_time: 0.5302  data_time: 0.0139  last_data_time: 0.0043   lr: 0.0002048  max_mem: 2457M\n","[06/10 17:38:29 d2.utils.events]:  eta: 0:01:19  iter: 839  total_loss: 0.616  loss_cls: 0.124  loss_box_reg: 0.2789  loss_mask: 0.2085  loss_rpn_cls: 0.001276  loss_rpn_loc: 0.01033    time: 0.4958  last_time: 0.5670  data_time: 0.0230  last_data_time: 0.0482   lr: 0.00020979  max_mem: 2457M\n","[06/10 17:38:39 d2.utils.events]:  eta: 0:01:09  iter: 859  total_loss: 0.6815  loss_cls: 0.1127  loss_box_reg: 0.3  loss_mask: 0.2258  loss_rpn_cls: 0.003395  loss_rpn_loc: 0.01697    time: 0.4956  last_time: 0.4957  data_time: 0.0190  last_data_time: 0.0065   lr: 0.00021479  max_mem: 2457M\n","[06/10 17:38:49 d2.utils.events]:  eta: 0:00:59  iter: 879  total_loss: 0.5861  loss_cls: 0.09668  loss_box_reg: 0.2776  loss_mask: 0.1994  loss_rpn_cls: 0.003199  loss_rpn_loc: 0.01269    time: 0.4957  last_time: 0.6263  data_time: 0.0171  last_data_time: 0.0738   lr: 0.00021978  max_mem: 2457M\n","[06/10 17:38:59 d2.utils.events]:  eta: 0:00:49  iter: 899  total_loss: 0.5058  loss_cls: 0.076  loss_box_reg: 0.2276  loss_mask: 0.1813  loss_rpn_cls: 0.0009178  loss_rpn_loc: 0.008711    time: 0.4954  last_time: 0.4567  data_time: 0.0181  last_data_time: 0.0031   lr: 0.00022478  max_mem: 2457M\n","[06/10 17:39:08 d2.utils.events]:  eta: 0:00:39  iter: 919  total_loss: 0.537  loss_cls: 0.0926  loss_box_reg: 0.2483  loss_mask: 0.1968  loss_rpn_cls: 0.001908  loss_rpn_loc: 0.01167    time: 0.4947  last_time: 0.4307  data_time: 0.0137  last_data_time: 0.0069   lr: 0.00022977  max_mem: 2457M\n","[06/10 17:39:18 d2.utils.events]:  eta: 0:00:29  iter: 939  total_loss: 0.559  loss_cls: 0.09718  loss_box_reg: 0.2488  loss_mask: 0.1964  loss_rpn_cls: 0.001965  loss_rpn_loc: 0.01059    time: 0.4943  last_time: 0.5101  data_time: 0.0140  last_data_time: 0.0105   lr: 0.00023477  max_mem: 2457M\n","[06/10 17:39:28 d2.utils.events]:  eta: 0:00:19  iter: 959  total_loss: 0.5408  loss_cls: 0.07538  loss_box_reg: 0.2501  loss_mask: 0.1859  loss_rpn_cls: 0.0004229  loss_rpn_loc: 0.01139    time: 0.4946  last_time: 0.5757  data_time: 0.0222  last_data_time: 0.0500   lr: 0.00023976  max_mem: 2457M\n","[06/10 17:39:37 d2.utils.events]:  eta: 0:00:09  iter: 979  total_loss: 0.5566  loss_cls: 0.07985  loss_box_reg: 0.27  loss_mask: 0.1828  loss_rpn_cls: 0.0009431  loss_rpn_loc: 0.01127    time: 0.4943  last_time: 0.4232  data_time: 0.0219  last_data_time: 0.0063   lr: 0.00024476  max_mem: 2457M\n","[06/10 17:39:49 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.5064  loss_cls: 0.08839  loss_box_reg: 0.2249  loss_mask: 0.1983  loss_rpn_cls: 0.001748  loss_rpn_loc: 0.01287    time: 0.4940  last_time: 0.5252  data_time: 0.0142  last_data_time: 0.0066   lr: 0.00024975  max_mem: 2457M\n","[06/10 17:39:49 d2.engine.hooks]: Overall training speed: 998 iterations in 0:08:12 (0.4940 s / it)\n","[06/10 17:39:49 d2.engine.hooks]: Total training time: 0:08:17 (0:00:04 on hooks)\n","[06/10 17:39:50 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from ./output/model_final.pth ...\n","[06/10 17:39:50 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n","[06/10 17:39:51 d2.data.datasets.coco]: Loaded 20 images in COCO format from ./coco/coco_annotations_noe_val.json\n","[06/10 17:39:51 d2.data.build]: Distribution of instances among all 1 categories:\n","|  category  | #instances   |\n","|:----------:|:-------------|\n","|   Human    | 73           |\n","|            |              |\n","[06/10 17:39:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[06/10 17:39:51 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[06/10 17:39:51 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n","[06/10 17:39:51 d2.data.common]: Serialized dataset takes 0.02 MiB\n","[06/10 17:39:51 d2.evaluation.evaluator]: Start inference on 20 batches\n","[06/10 17:39:54 d2.evaluation.evaluator]: Inference done 11/20. Dataloading: 0.1473 s/iter. Inference: 0.1140 s/iter. Eval: 0.0055 s/iter. Total: 0.2668 s/iter. ETA=0:00:02\n","[06/10 17:39:57 d2.evaluation.evaluator]: Total inference time: 0:00:04.184530 (0.278969 s / iter per device, on 1 devices)\n","[06/10 17:39:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:01 (0.112351 s / iter per device, on 1 devices)\n","[06/10 17:39:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[06/10 17:39:57 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n","[06/10 17:39:57 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.02s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.878\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.617\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.608\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.545\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\n","[06/10 17:39:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 53.821 | 87.753 | 61.738 | 0.000 | 48.372 | 58.697 |\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *segm*\n","DONE (t=0.03s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.892\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.606\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.573\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.588\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.545\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n","[06/10 17:39:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 52.993 | 89.205 | 60.646 | 0.000 | 48.642 | 57.276 |\n"]}],"source":["for name in names.keys():\n","    os.chdir(\"/content/drive/MyDrive/Python_HN\")\n","    predictor,metadata = exec_d2(name,names[name])\n","    os.chdir('classify_dirs')\n","    os.mkdir(name)\n","    classify(name,predictor)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5","timestamp":1679564620762}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":0}